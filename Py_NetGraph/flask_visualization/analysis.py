import networkx as nx
import numpy as np
import matplotlib.cm as cm
import matplotlib.colors as mcolors
import pandas as pd

from database import fetch_data  # ç¡®ä¿æ•°æ®åº“è¿æ¥å’ŒæŸ¥è¯¢å‡½æ•°æ­£ç¡®


def analyze_friends():
    """è·å–å¥½å‹å…³ç³»æ•°æ®å¹¶è®¡ç®—èŠ‚ç‚¹å±æ€§ï¼ŒåŒ…å«æ‰€æœ‰ç”¨æˆ·"""
    query_users = "SELECT id, username FROM users"
    df_users = fetch_data(query_users)

    query_friends = """
        SELECT f.user_id, u1.username AS user_name_1, 
               f.friend_id, u2.username AS user_name_2
        FROM friends f
        JOIN users u1 ON f.user_id = u1.id
        JOIN users u2 ON f.friend_id = u2.id
    """
    df_friends = fetch_data(query_friends)

    # æ„å»ºæ— å‘å›¾
    G = nx.Graph()
    user_map = {row["id"]: row["username"] for _, row in df_users.iterrows()}  # è®°å½•æ‰€æœ‰ç”¨æˆ·

    # æ·»åŠ è¾¹
    for _, row in df_friends.iterrows():
        G.add_edge(row["user_id"], row["friend_id"])

    # è®¡ç®—å¥½å‹æ•°é‡
    degrees = {node: G.degree(node) for node in G.nodes()}

    # è®©æ‰€æœ‰ç”¨æˆ·éƒ½å‚ä¸è®¡ç®—ï¼ˆåŒ…æ‹¬æ²¡æœ‰å¥½å‹çš„ï¼‰
    for user_id in user_map.keys():
        if user_id not in degrees:
            degrees[user_id] = 0  # æ— å¥½å‹

    degree_values = list(degrees.values())
    vmin, vmax = min(degree_values), max(degree_values)

    # ğŸ¨ é¢œè‰²åˆ’åˆ†
    bins = np.linspace(vmin, vmax, 6)
    colors = [cm.Paired(i / 5) for i in range(6)]

    node_colors = [
        mcolors.to_hex(colors[np.digitize(degrees[user_id], bins) - 1])
        for user_id in user_map.keys()
    ]

    node_sizes = [
        np.interp(degrees[user_id], (vmin, vmax), (600, 5000))
        for user_id in user_map.keys()
    ]

    # æ„é€  JSON
    nodes = [{"id": int(user_id), "username": user_map[user_id], "size": node_sizes[i], "color": node_colors[i],
              "degree": degrees[user_id]}
             for i, user_id in enumerate(user_map.keys())]

    edges = [{"source": int(u), "target": int(v)} for u, v in G.edges()]

    return {"nodes": nodes, "edges": edges}


def analyze_messages():
    """è·å–æ¶ˆæ¯äº’åŠ¨æ•°æ®å¹¶è®¡ç®—èŠ‚ç‚¹å±æ€§ï¼ŒåŒ…å«æ‰€æœ‰ç”¨æˆ·"""
    query_users = "SELECT id, username FROM users"
    df_users = fetch_data(query_users)

    query_messages = """
        SELECT m.sender_id, u1.username AS sender_name,
               m.receiver_id, u2.username AS receiver_name,
               COUNT(*) as weight
        FROM messages m
        JOIN users u1 ON m.sender_id = u1.id
        JOIN users u2 ON m.receiver_id = u2.id
        GROUP BY m.sender_id, m.receiver_id
    """
    df_messages = fetch_data(query_messages)

    # æ„å»ºæœ‰å‘å›¾
    G = nx.DiGraph()
    user_map = {row["id"]: row["username"] for _, row in df_users.iterrows()}

    # æ·»åŠ è¾¹
    for _, row in df_messages.iterrows():
        G.add_edge(row["sender_id"], row["receiver_id"], weight=row["weight"])

    # è®¡ç®—æ´»è·ƒåº¦ï¼ˆå…¥åº¦+å‡ºåº¦ï¼‰
    node_activity = {node: sum(d["weight"] for _, _, d in G.edges(node, data=True)) for node in G.nodes()}

    # ç¡®ä¿æ‰€æœ‰ç”¨æˆ·éƒ½åŒ…å«ï¼Œå³ä½¿æ²¡å‘è¿‡æ¶ˆæ¯
    for user_id in user_map.keys():
        if user_id not in node_activity:
            node_activity[user_id] = 0  # æ²¡æœ‰å‘é€/æ¥æ”¶æ¶ˆæ¯

    activity_values = list(node_activity.values())
    vmin, vmax = min(activity_values), max(activity_values)

    # ğŸ¨ é¢œè‰²åˆ’åˆ†
    bins = np.linspace(vmin, vmax, 6)
    colors = [cm.viridis(i / 5) for i in range(6)]

    node_colors = [
        mcolors.to_hex(colors[np.digitize(node_activity[user_id], bins) - 1])
        for user_id in user_map.keys()
    ]

    node_sizes = [
        np.interp(node_activity[user_id], (vmin, vmax), (1000, 6000))
        for user_id in user_map.keys()
    ]

    # æ„é€  JSON
    nodes = [{
        "id": int(user_id),
        "username": user_map[user_id],
        "size": node_sizes[i],
        "color": node_colors[i],
        "activity": node_activity[user_id]
    } for i, user_id in enumerate(user_map.keys())]

    edges = [{
        "source": int(u),
        "target": int(v),
        "weight": G[u][v]["weight"]
    } for u, v in G.edges()]

    return {"nodes": nodes, "edges": edges}


def analyze_by_timestamp():
    """è·å–æ¶ˆæ¯äº’åŠ¨æ•°æ®å¹¶è®¡ç®—æ—¶é—´åºåˆ—å±æ€§"""
    query = "SELECT timestamp FROM messages"
    df_time = fetch_data(query)

    # å¤„ç†æ—¶é—´æ•°æ®
    df_time["timestamp"] = pd.to_datetime(df_time["timestamp"])

    # æŒ‰æ—¶é—´æˆ³åˆ†ç»„ï¼Œç»Ÿè®¡æ¯ä¸ªæ—¶é—´ç‚¹çš„æ¶ˆæ¯æ•°é‡
    msg_count = df_time.groupby(df_time["timestamp"]).size()

    # å¹³æ»‘å¤„ç†ï¼šä½¿ç”¨æ»šåŠ¨å¹³å‡
    window_size = 10  # è®¾ç½®çª—å£å¤§å°
    msg_count_smoothed = msg_count.rolling(window=window_size, min_periods=1).mean()

    # å½’ä¸€åŒ–æ—¶é—´æˆ³ï¼Œç”¨äº JSON è¾“å‡º
    timestamps = msg_count.index.astype(str).tolist()
    smoothed_values = msg_count_smoothed.tolist()

    # æ„é€  JSON ç»“æœ
    time_series = [{"timestamp": timestamps[i], "count": smoothed_values[i]} for i in range(len(timestamps))]

    return {"time_series": time_series}


def analyze_friend_distribution():
    """è®¡ç®—å¥½å‹æ•°é‡çš„åˆ†å¸ƒï¼Œå¹¶è¿”å› JSON ç»“æœ"""
    # è·å–å¥½å‹å…³ç³»æ•°æ®
    query = """
        SELECT f.user_id, u.username AS user_name
        FROM friends f
        JOIN users u ON f.user_id = u.id
    """
    df_friends = fetch_data(query)

    # è®¡ç®—æ¯ä¸ªç”¨æˆ·çš„å¥½å‹æ•°é‡
    friend_counts = df_friends["user_id"].value_counts()

    # è®¡ç®—å‡å€¼å’Œä¸­ä½æ•°
    mean_friends = friend_counts.mean()
    median_friends = friend_counts.median()

    # é¢œè‰²æ˜ å°„
    bins = np.linspace(friend_counts.min(), friend_counts.max(), 6)
    colors = [cm.Blues(i / 5) for i in range(6)]  # 6 çº§é¢œè‰²
    color_map = {count: mcolors.to_hex(colors[np.digitize(count, bins) - 1]) for count in friend_counts}

    # æ„é€  JSON ç»“æœ
    friend_data = [
        {"user_id": int(user), "friend_count": int(count), "color": color_map[count]}
        for user, count in friend_counts.items()
    ]

    return {
        "friend_data": friend_data,
        "stats": {"mean_friends": mean_friends, "median_friends": median_friends}
    }
