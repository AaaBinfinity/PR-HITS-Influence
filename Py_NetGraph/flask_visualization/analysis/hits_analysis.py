from datetime import datetime, timedelta
import networkx as nx
from database import fetch_data

def analyze_messages_hits(days=30):
    """
    æ ¹æ®æ¶ˆæ¯æ•°æ®å’Œç¤¾äº¤ç¤¾åŒºè®¡ç®— HITS ç®—æ³•çš„ hub å’Œ authority å€¼ã€‚

    Parameters:
        days (int): æŒ‡å®šåˆ†æçš„æ—¶é—´èŒƒå›´ï¼ˆé»˜è®¤ä¸º30å¤©ï¼‰ã€‚

    Returns:
        hub_scores (dict): åŒ…å«æ¯ä¸ªèŠ‚ç‚¹çš„ hub å€¼ã€‚
        authority_scores (dict): åŒ…å«æ¯ä¸ªèŠ‚ç‚¹çš„ authority å€¼ã€‚
        user_map (dict): ç”¨æˆ·IDä¸ç”¨æˆ·åçš„æ˜ å°„ã€‚
        community_ids (dict): ç”¨æˆ·IDä¸æ‰€å±ç¤¾åŒºçš„æ˜ å°„ã€‚
        df_messages (DataFrame): è·å–çš„æ¶ˆæ¯äº¤äº’æ•°æ®ã€‚
    """

    # è®¡ç®—æ—¶é—´èŒƒå›´ï¼Œè·å–å½“å‰æ—¥æœŸå‰ "days" å¤©çš„æ—¥æœŸ
    one_month_ago = datetime.now() - timedelta(days=days)
    one_month_ago_str = one_month_ago.strftime('%Y-%m-%d %H:%M:%S')

    # è·å–æ‰€æœ‰ç”¨æˆ·ä¿¡æ¯
    query_users = "SELECT id, username FROM users"
    df_users = fetch_data(query_users)

    # è·å–æœ€è¿‘ days å¤©çš„æ¶ˆæ¯æ•°æ®
    query_messages = f"""
        SELECT m.sender_id, u1.username AS sender_name,
               m.receiver_id, u2.username AS receiver_name,
               COUNT(*) as weight
        FROM messages m
        JOIN users u1 ON m.sender_id = u1.id
        JOIN users u2 ON m.receiver_id = u2.id
        WHERE m.timestamp >= '{one_month_ago_str}'
        GROUP BY m.sender_id, m.receiver_id
    """
    df_messages = fetch_data(query_messages)

    # å¦‚æœæ²¡æœ‰æ¶ˆæ¯æ•°æ®ï¼Œåˆ™è¿”å›ç©ºæ•°æ®
    if df_messages.empty:
        print("âš ï¸ df_messages ä¸ºç©ºï¼Œæ²¡æœ‰äº¤äº’æ•°æ®")
        return {}, {}, {}, df_messages

    # **åˆ›å»ºæœ‰å‘å›¾**ï¼ˆç¤¾äº¤ç½‘ç»œå›¾ï¼‰
    G = nx.DiGraph()

    # **æ„å»ºç”¨æˆ·æ˜ å°„è¡¨**
    user_map = {row["id"]: row["username"] for _, row in df_users.iterrows()}

    if not user_map:
        print("âš ï¸ user_map ä¸ºç©ºï¼Œå¯èƒ½ users è¡¨æ— æ•°æ®")
        return {}, {}, {}, df_messages

    # **æ·»åŠ è¾¹ï¼ˆæ¶ˆæ¯äº¤äº’ï¼‰åˆ°å›¾ä¸­**
    for _, row in df_messages.iterrows():
        G.add_edge(int(row["sender_id"]), int(row["receiver_id"]), weight=float(row["weight"]))

    # å¦‚æœå›¾æ²¡æœ‰è¾¹ï¼Œè¿”å›ç©ºæ•°æ®
    if not G.edges:
        print("âš ï¸ G.edges ä¸ºç©ºï¼ŒHITS è®¡ç®—æ— æ³•è¿›è¡Œ")
        return {}, {}, user_map, df_messages

    print(f"ğŸ“Š å›¾åŒ…å« {G.number_of_nodes()} ä¸ªèŠ‚ç‚¹, {G.number_of_edges()} æ¡è¾¹")

    # **æ£€æµ‹ç¤¾åŒºï¼ˆè¿é€šå­å›¾ï¼‰**
    communities = list(nx.weakly_connected_components(G))
    print(f"ğŸ” æ£€æµ‹åˆ° {len(communities)} ä¸ªç‹¬ç«‹ç¤¾äº¤ç¤¾åŒº")

    # **ç‹¬ç«‹è®¡ç®—æ¯ä¸ªç¤¾åŒºçš„ HITS**
    hub_scores = {}
    authority_scores = {}
    community_ids = {}

    for i, community in enumerate(communities):
        subG = G.subgraph(community).copy()  # è·å–æ¯ä¸ªç¤¾åŒºçš„å­å›¾
        print(f"ğŸ“Œ è®¡ç®—ç¤¾åŒº {i+1}, åŒ…å« {subG.number_of_nodes()} ä¸ªèŠ‚ç‚¹, {subG.number_of_edges()} æ¡è¾¹")

        try:
            # è®¡ç®—è¯¥å­å›¾çš„ HITS åˆ†æ•°
            hits_scores = nx.hits(subG, max_iter=1000, tol=1e-15, normalized=True)
            sub_hub_scores, sub_authority_scores = hits_scores
        except nx.PowerIterationFailedConvergence:
            # å¦‚æœè®¡ç®—æœªæ”¶æ•›ï¼Œä½¿ç”¨å…¥åº¦å’Œå‡ºåº¦æ›¿ä»£
            print(f"âš ï¸ ç¤¾åŒº {i+1} HITS è®¡ç®—æœªæ”¶æ•›ï¼Œæ”¹ç”¨å…¥åº¦/å‡ºåº¦è®¡ç®—")
            sub_hub_scores = {node: subG.out_degree(node, weight="weight") for node in subG.nodes()}
            sub_authority_scores = {node: subG.in_degree(node, weight="weight") for node in subG.nodes()}

        # åˆå¹¶åˆ°æ€»ç»“æœä¸­
        hub_scores.update(sub_hub_scores)
        authority_scores.update(sub_authority_scores)

        # è®°å½•æ¯ä¸ªç”¨æˆ·æ‰€å±çš„ç¤¾åŒºID
        for node in community:
            community_ids[node] = i  # Community ID is the index of the community

    return hub_scores, authority_scores, user_map, community_ids, df_messages


def get_messages_hits_data(days=30):
    """
    è¿”å›åŒ…å« hubã€authority å’Œ community_id çš„èŠ‚ç‚¹æ•°æ®ï¼Œé€‚ç”¨äºå‰ç«¯å¯è§†åŒ–ã€‚

    Parameters:
        days (int): æŒ‡å®šåˆ†æçš„æ—¶é—´èŒƒå›´ï¼ˆé»˜è®¤ä¸º30å¤©ï¼‰ã€‚

    Returns:
        dict: åŒ…å«èŠ‚ç‚¹æ•°æ®ï¼ˆhubã€authorityã€community_idï¼‰å’Œè¾¹æ•°æ®ï¼ˆæ¶ˆæ¯äº¤äº’ï¼‰ã€‚
    """
    # è°ƒç”¨åˆ†æå‡½æ•°ï¼Œè·å– HITS ç»“æœ
    hub_scores, authority_scores, user_map, community_ids, df_messages = analyze_messages_hits(days)

    # æ„é€ èŠ‚ç‚¹æ•°æ®ï¼Œæ¯ä¸ªèŠ‚ç‚¹åŒ…å« idã€ç”¨æˆ·åã€hub å€¼ã€authority å€¼ã€å¤§å°ã€ç¤¾åŒº ID ç­‰ä¿¡æ¯
    nodes = [
        {
            "id": int(user_id),
            "username": user_map[user_id],
            "authority": round(authority_scores.get(user_id, 0), 6),
            "hub": round(hub_scores.get(user_id, 0), 6),
            "size": int((authority_scores.get(user_id, 0) + hub_scores.get(user_id, 0)) * 1000),
            "community_id": community_ids.get(user_id, -1)  # é»˜è®¤ -1 è¡¨ç¤ºæ²¡æœ‰åˆ†é…ç¤¾åŒº ID
        }
        for user_id in user_map.keys()
    ]

    # æ„é€ è¾¹æ•°æ®ï¼Œè¡¨ç¤ºç”¨æˆ·é—´çš„æ¶ˆæ¯äº¤äº’
    edges = [
        {"source": int(row["sender_id"]), "target": int(row["receiver_id"]), "weight": float(row["weight"])}
        for _, row in df_messages.iterrows()
    ]

    # è¿”å›åŒ…å«èŠ‚ç‚¹å’Œè¾¹æ•°æ®çš„å­—å…¸
    return {"nodes": nodes, "edges": edges}
