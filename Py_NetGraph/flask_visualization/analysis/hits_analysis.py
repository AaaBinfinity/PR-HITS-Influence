"""
HITS
"""
from datetime import datetime, timedelta
import networkx as nx
from database import fetch_data



def analyze_messages_hits(days=30):
    """æŒ‰ç¤¾äº¤ç¤¾åŒºç‹¬ç«‹è®¡ç®— HITS ç®—æ³•çš„ hub å’Œ authority å€¼"""

    # è®¡ç®—æ—¶é—´èŒƒå›´
    one_month_ago = datetime.now() - timedelta(days=days)
    one_month_ago_str = one_month_ago.strftime('%Y-%m-%d %H:%M:%S')

    # è·å–æ‰€æœ‰ç”¨æˆ·
    query_users = "SELECT id, username FROM users"
    df_users = fetch_data(query_users)

    # è·å–æœ€è¿‘ days å¤©çš„æ¶ˆæ¯æ•°æ®
    query_messages = f"""
        SELECT m.sender_id, u1.username AS sender_name,
               m.receiver_id, u2.username AS receiver_name,
               COUNT(*) as weight
        FROM messages m
        JOIN users u1 ON m.sender_id = u1.id
        JOIN users u2 ON m.receiver_id = u2.id
        WHERE m.timestamp >= '{one_month_ago_str}'
        GROUP BY m.sender_id, m.receiver_id
    """
    df_messages = fetch_data(query_messages)

    if df_messages.empty:
        print("âš ï¸ df_messages ä¸ºç©ºï¼Œæ²¡æœ‰äº¤äº’æ•°æ®")
        return {}, {}, {}, df_messages

    # **åˆ›å»ºæœ‰å‘å›¾**
    G = nx.DiGraph()

    # **æ„å»ºç”¨æˆ·æ˜ å°„è¡¨**
    user_map = {row["id"]: row["username"] for _, row in df_users.iterrows()}

    if not user_map:
        print("âš ï¸ user_map ä¸ºç©ºï¼Œå¯èƒ½ users è¡¨æ— æ•°æ®")
        return {}, {}, {}, df_messages

    # **æ·»åŠ è¾¹ï¼ˆæ¶ˆæ¯äº¤äº’ï¼‰**
    for _, row in df_messages.iterrows():
        G.add_edge(int(row["sender_id"]), int(row["receiver_id"]), weight=float(row["weight"]))

    if not G.edges:
        print("âš ï¸ G.edges ä¸ºç©ºï¼ŒHITS è®¡ç®—æ— æ³•è¿›è¡Œ")
        return {}, {}, user_map, df_messages

    print(f"ğŸ“Š å›¾åŒ…å« {G.number_of_nodes()} ä¸ªèŠ‚ç‚¹, {G.number_of_edges()} æ¡è¾¹")

    # **æ£€æµ‹ç¤¾åŒºï¼ˆè¿é€šå­å›¾ï¼‰**
    communities = list(nx.weakly_connected_components(G))
    print(f"ğŸ” æ£€æµ‹åˆ° {len(communities)} ä¸ªç‹¬ç«‹ç¤¾äº¤ç¤¾åŒº")

    # **ç‹¬ç«‹è®¡ç®— HITS**
    hub_scores = {}
    authority_scores = {}
    community_ids = {}

    for i, community in enumerate(communities):
        subG = G.subgraph(community).copy()
        print(f"ğŸ“Œ è®¡ç®—ç¤¾åŒº {i+1}, åŒ…å« {subG.number_of_nodes()} ä¸ªèŠ‚ç‚¹, {subG.number_of_edges()} æ¡è¾¹")

        try:
            hits_scores = nx.hits(subG, max_iter=1000, tol=1e-15, normalized=True)
            sub_hub_scores, sub_authority_scores = hits_scores
        except nx.PowerIterationFailedConvergence:
            print(f"âš ï¸ ç¤¾åŒº {i+1} HITS è®¡ç®—æœªæ”¶æ•›ï¼Œæ”¹ç”¨å…¥åº¦/å‡ºåº¦è®¡ç®—")
            sub_hub_scores = {node: subG.out_degree(node, weight="weight") for node in subG.nodes()}
            sub_authority_scores = {node: subG.in_degree(node, weight="weight") for node in subG.nodes()}

        # åˆå¹¶åˆ°æ€»ç»“æœ
        hub_scores.update(sub_hub_scores)
        authority_scores.update(sub_authority_scores)

        # è®°å½•ç¤¾åŒºID
        for node in community:
            community_ids[node] = i  # Community ID is the index of the community

    return hub_scores, authority_scores, user_map, community_ids, df_messages


def get_messages_hits_data(days=30):
    """è¿”å›åŒ…å« hubã€authority å’Œ community_id çš„æ•°æ®"""
    hub_scores, authority_scores, user_map, community_ids, df_messages = analyze_messages_hits(days)

    nodes = [
        {
            "id": int(user_id),
            "username": user_map[user_id],
            "authority": round(authority_scores.get(user_id, 0), 6),
            "hub": round(hub_scores.get(user_id, 0), 6),
            "size": int((authority_scores.get(user_id, 0) + hub_scores.get(user_id, 0)) * 1000),
            "community_id": community_ids.get(user_id, -1)  # Default to -1 if no community ID
        }
        for user_id in user_map.keys()
    ]

    edges = [
        {"source": int(row["sender_id"]), "target": int(row["receiver_id"]), "weight": float(row["weight"])}
        for _, row in df_messages.iterrows()
    ]

    return {"nodes": nodes, "edges": edges}



