"""
PageRank
"""
import colorsys
from collections import defaultdict
from datetime import datetime, timedelta

import networkx as nx
import numpy as np
import matplotlib.cm as cm
import matplotlib.colors as mcolors
from community import community_louvain

from database import fetch_data


def analyze_messages_pagerank():
    """ä½¿ç”¨ PageRank ç®—æ³•è®¡ç®—ç”¨æˆ·ä¼ æ’­æ€§ï¼ˆä»…é‡‡é›†æœ€è¿‘ä¸€ä¸ªæœˆçš„æ•°æ®ï¼‰"""

    # è®¡ç®—æœ€è¿‘ä¸€ä¸ªæœˆçš„æ—¶é—´èŒƒå›´
    one_month_ago = datetime.now() - timedelta(days=30)
    one_month_ago_str = one_month_ago.strftime('%Y-%m-%d %H:%M:%S')

    # æŸ¥è¯¢æ‰€æœ‰ç”¨æˆ·ä¿¡æ¯
    query_users = "SELECT id, username FROM users"
    df_users = fetch_data(query_users)

    # æŸ¥è¯¢æœ€è¿‘ä¸€ä¸ªæœˆçš„æ¶ˆæ¯äº’åŠ¨æ•°æ®
    query_messages = f"""
        SELECT m.sender_id, u1.username AS sender_name,
               m.receiver_id, u2.username AS receiver_name,
               COUNT(*) as weight
        FROM messages m
        JOIN users u1 ON m.sender_id = u1.id
        JOIN users u2 ON m.receiver_id = u2.id
        WHERE m.timestamp >= '{one_month_ago_str}'
        GROUP BY m.sender_id, m.receiver_id
    """
    df_messages = fetch_data(query_messages)

    # æ„å»ºæœ‰å‘å›¾
    G = nx.DiGraph()
    user_map = {row["id"]: row["username"] for _, row in df_users.iterrows()}

    # æ·»åŠ å¸¦æƒé‡çš„è¾¹ï¼ˆæ¶ˆæ¯ä¼ æ’­ï¼‰
    for _, row in df_messages.iterrows():
        G.add_edge(row["sender_id"], row["receiver_id"], weight=row["weight"])

    # ç¡®ä¿æ‰€æœ‰ç”¨æˆ·éƒ½ä½œä¸ºèŠ‚ç‚¹
    G.add_nodes_from(df_users['id'])

    # è®¡ç®— PageRank å€¼
    pagerank_scores = nx.pagerank(G, weight='weight')

    # å½’ä¸€åŒ– PageRank ç»“æœ
    scores_values = np.array(list(pagerank_scores.values()))
    vmin, vmax = scores_values.min(), scores_values.max() if len(scores_values) > 0 else (0, 1)

    # é¢œè‰²åˆ’åˆ†
    bins = np.linspace(vmin, vmax, 6)
    colors = [cm.viridis(i / 5) for i in range(6)]

    # ä¸ºæ¯ä¸ªèŠ‚ç‚¹åˆ†é…é¢œè‰²å’Œå¤§å°
    node_colors = [
        mcolors.to_hex(colors[np.digitize(pagerank_scores.get(user_id, 0), bins) - 1])
        for user_id in user_map.keys()
    ]
    node_sizes = [
        np.interp(pagerank_scores.get(user_id, 0), (vmin, vmax), (1000, 6000))
        for user_id in user_map.keys()
    ]

    # æ„é€  JSON æ ¼å¼çš„èŠ‚ç‚¹æ•°æ®
    nodes = [{
        "id": int(user_id),
        "username": user_map[user_id],
        "size": node_sizes[i],
        "color": node_colors[i],
        "pagerank": pagerank_scores.get(user_id, 0)
    } for i, user_id in enumerate(user_map.keys())]

    # æ„é€ è¾¹æ•°æ®
    edges = [{
        "source": int(u),
        "target": int(v),
        "weight": G[u][v]["weight"]
    } for u, v in G.edges()]

    return {"nodes": nodes, "edges": edges}

def analyze_messages_hits(days=30):
    """æŒ‰ç¤¾äº¤ç¤¾åŒºç‹¬ç«‹è®¡ç®— HITS ç®—æ³•çš„ hub å’Œ authority å€¼"""

    # è®¡ç®—æ—¶é—´èŒƒå›´
    one_month_ago = datetime.now() - timedelta(days=days)
    one_month_ago_str = one_month_ago.strftime('%Y-%m-%d %H:%M:%S')

    # è·å–æ‰€æœ‰ç”¨æˆ·
    query_users = "SELECT id, username FROM users"
    df_users = fetch_data(query_users)

    # è·å–æœ€è¿‘ days å¤©çš„æ¶ˆæ¯æ•°æ®
    query_messages = f"""
        SELECT m.sender_id, u1.username AS sender_name,
               m.receiver_id, u2.username AS receiver_name,
               COUNT(*) as weight
        FROM messages m
        JOIN users u1 ON m.sender_id = u1.id
        JOIN users u2 ON m.receiver_id = u2.id
        WHERE m.timestamp >= '{one_month_ago_str}'
        GROUP BY m.sender_id, m.receiver_id
    """
    df_messages = fetch_data(query_messages)

    if df_messages.empty:
        print("âš ï¸ df_messages ä¸ºç©ºï¼Œæ²¡æœ‰äº¤äº’æ•°æ®")
        return {}, {}, {}, df_messages

    # **åˆ›å»ºæœ‰å‘å›¾**
    G = nx.DiGraph()

    # **æ„å»ºç”¨æˆ·æ˜ å°„è¡¨**
    user_map = {row["id"]: row["username"] for _, row in df_users.iterrows()}

    if not user_map:
        print("âš ï¸ user_map ä¸ºç©ºï¼Œå¯èƒ½ users è¡¨æ— æ•°æ®")
        return {}, {}, {}, df_messages

    # **æ·»åŠ è¾¹ï¼ˆæ¶ˆæ¯äº¤äº’ï¼‰**
    for _, row in df_messages.iterrows():
        G.add_edge(int(row["sender_id"]), int(row["receiver_id"]), weight=float(row["weight"]))

    if not G.edges:
        print("âš ï¸ G.edges ä¸ºç©ºï¼ŒHITS è®¡ç®—æ— æ³•è¿›è¡Œ")
        return {}, {}, user_map, df_messages

    print(f"ğŸ“Š å›¾åŒ…å« {G.number_of_nodes()} ä¸ªèŠ‚ç‚¹, {G.number_of_edges()} æ¡è¾¹")

    # **æ£€æµ‹ç¤¾åŒºï¼ˆè¿é€šå­å›¾ï¼‰**
    communities = list(nx.weakly_connected_components(G))
    print(f"ğŸ” æ£€æµ‹åˆ° {len(communities)} ä¸ªç‹¬ç«‹ç¤¾äº¤ç¤¾åŒº")

    # **ç‹¬ç«‹è®¡ç®— HITS**
    hub_scores = {}
    authority_scores = {}
    community_ids = {}

    for i, community in enumerate(communities):
        subG = G.subgraph(community).copy()
        print(f"ğŸ“Œ è®¡ç®—ç¤¾åŒº {i+1}, åŒ…å« {subG.number_of_nodes()} ä¸ªèŠ‚ç‚¹, {subG.number_of_edges()} æ¡è¾¹")

        try:
            hits_scores = nx.hits(subG, max_iter=1000, tol=1e-15, normalized=True)
            sub_hub_scores, sub_authority_scores = hits_scores
        except nx.PowerIterationFailedConvergence:
            print(f"âš ï¸ ç¤¾åŒº {i+1} HITS è®¡ç®—æœªæ”¶æ•›ï¼Œæ”¹ç”¨å…¥åº¦/å‡ºåº¦è®¡ç®—")
            sub_hub_scores = {node: subG.out_degree(node, weight="weight") for node in subG.nodes()}
            sub_authority_scores = {node: subG.in_degree(node, weight="weight") for node in subG.nodes()}

        # åˆå¹¶åˆ°æ€»ç»“æœ
        hub_scores.update(sub_hub_scores)
        authority_scores.update(sub_authority_scores)

        # è®°å½•ç¤¾åŒºID
        for node in community:
            community_ids[node] = i  # Community ID is the index of the community

    return hub_scores, authority_scores, user_map, community_ids, df_messages


def get_messages_hits_data(days=30):
    """è¿”å›åŒ…å« hubã€authority å’Œ community_id çš„æ•°æ®"""
    hub_scores, authority_scores, user_map, community_ids, df_messages = analyze_messages_hits(days)

    nodes = [
        {
            "id": int(user_id),
            "username": user_map[user_id],
            "authority": round(authority_scores.get(user_id, 0), 6),
            "hub": round(hub_scores.get(user_id, 0), 6),
            "size": int((authority_scores.get(user_id, 0) + hub_scores.get(user_id, 0)) * 1000),
            "community_id": community_ids.get(user_id, -1)  # Default to -1 if no community ID
        }
        for user_id in user_map.keys()
    ]

    edges = [
        {"source": int(row["sender_id"]), "target": int(row["receiver_id"]), "weight": float(row["weight"])}
        for _, row in df_messages.iterrows()
    ]

    return {"nodes": nodes, "edges": edges}


def analyze_community():
    """è·å–ç”¨æˆ·ç¤¾åŒºåˆ’åˆ†æ•°æ®"""
    # æŸ¥è¯¢æ‰€æœ‰ç”¨æˆ·ä¿¡æ¯
    query_users = "SELECT id, username FROM users"
    df_users = fetch_data(query_users)

    # æŸ¥è¯¢å¥½å‹å…³ç³»æ•°æ®
    query_friends = """
        SELECT f.user_id, u1.username AS user_name_1, 
               f.friend_id, u2.username AS user_name_2
        FROM friends f
        JOIN users u1 ON f.user_id = u1.id
        JOIN users u2 ON f.friend_id = u2.id
    """
    df_friends = fetch_data(query_friends)

    # æ„å»ºæ— å‘å›¾
    G = nx.Graph()
    user_map = {row["id"]: row["username"] for _, row in df_users.iterrows()}  # è®°å½•æ‰€æœ‰ç”¨æˆ·

    # æ·»åŠ è¾¹ï¼ˆå¥½å‹å…³ç³»ï¼‰
    for _, row in df_friends.iterrows():
        G.add_edge(row["user_id"], row["friend_id"])

    # ä½¿ç”¨ Louvain ç®—æ³•è¿›è¡Œç¤¾åŒºåˆ’åˆ†
    partition = community_louvain.best_partition(G)

    # ä¸ºæ¯ä¸ªç¤¾åŒºåˆ†é…é¢œè‰²å’Œç”¨æˆ·
    community_map = defaultdict(list)
    for user_id, community_id in partition.items():
        community_map[community_id].append(user_id)

    # å¤„ç†æ²¡æœ‰åˆ†é…åˆ°ç¤¾åŒºçš„ç”¨æˆ·
    default_community = len(community_map)  # è®¾ç½®ä¸€ä¸ªé»˜è®¤ç¤¾åŒºID
    for user_id in user_map.keys():
        if user_id not in partition:
            partition[user_id] = default_community  # å°†æœªåˆ†é…ç¤¾åŒºçš„ç”¨æˆ·åˆ†é…åˆ°é»˜è®¤ç¤¾åŒº
            community_map[default_community].append(user_id)

    # ä¸ºæ¯ä¸ªç¤¾åŒºåˆ†é…é¢œè‰²
    colors = [
        '#' + ''.join([hex(int(c * 255))[2:].zfill(2) for c in colorsys.hsv_to_rgb(i / len(community_map), 1, 1)])
        for i in range(len(community_map))
    ]
    # æ„é€ èŠ‚ç‚¹æ•°æ®å’Œè¾¹æ•°æ®
    nodes = [
        {"id": int(user_id), "username": user_map.get(user_id, "æœªçŸ¥ç”¨æˆ·"),
         "community": partition.get(user_id), "color": colors[partition[user_id]]}
        for user_id in user_map.keys()
    ]
    edges = [{"source": int(u), "target": int(v)} for u, v in G.edges()]

    return {"nodes": nodes, "edges": edges, "community_map": community_map, "colors": colors}
